torch._C._set_grad_enabled(False)
torch.Tensor.shape.__get__(Tensor([1, 21], "int64"))
torch.Tensor.device.__get__(Tensor([1, 21], "int64"))
torch.tensor(1, device="cuda:0", dtype="int64")
torch.tensor(2, device="cuda:0", dtype="int64")
torch.tensor(0, device="cuda:0", dtype="int64")
torch.Tensor.ndim.__get__(Tensor([], "int64"))
torch.Tensor.unsqueeze(Tensor([], "int64"), 0)
torch.Tensor.device.__get__(Tensor([1], "int64"))
torch.isin(Tensor([1], "int64"), Tensor([], "int64"))
torch.Tensor.any(Tensor([1], "bool"))
torch.Tensor.__bool__(Tensor([], "bool"))
torch.is_floating_point(Tensor([1], "int64"))
torch.Tensor.lt(Tensor([1], "int64"), 0)
torch.Tensor.any(Tensor([1], "bool"))
torch.Tensor.__bool__(Tensor([], "bool"))
torch.Tensor.shape.__get__(Tensor([1, 21], "int64"))
torch.Tensor.device.__get__(Tensor([1, 21], "int64"))
torch.ones(tuple(1, 21), dtype="int64", device="cuda:0")
torch.Tensor.shape.__get__(Tensor([1, 21], "int64"))
torch.Tensor.dtype.__get__(Tensor([1, 21], "int64"))
torch.Tensor.device.__get__(Tensor([1, 21], "int64"))
torch.isin(Tensor([1, 21], "int64"), Tensor([], "int64"))
torch.Tensor.any(Tensor([1, 21], "bool"))
torch.Tensor.device.__get__(Tensor([1], "int64"))
torch.isin(Tensor([1], "int64"), Tensor([], "int64"))
torch.Tensor.any(Tensor([1], "bool"))
torch.Tensor.__invert__(Tensor([], "bool"))
torch.Tensor.mul(Tensor([], "bool"), Tensor([], "bool"))
torch.Tensor.ne(Tensor([1, 21], "int64"), Tensor([], "int64"))
torch.Tensor.long(Tensor([1, 21], "bool"))
torch.Tensor.mul(Tensor([1, 21], "int64"), Tensor([], "bool"))
torch.Tensor.__invert__(Tensor([], "bool"))
torch.Tensor.mul(Tensor([1, 21], "int64"), Tensor([], "bool"))
torch.Tensor.add(Tensor([1, 21], "int64"), Tensor([1, 21], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 21], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 21], "int64"))
torch.Tensor.device.__get__(Tensor([32000, 2048], "float32"))
torch.Tensor.device.__get__(Tensor([1, 21], "int64"))
torch.Tensor.device.__get__(Tensor([1, 21], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 21], "int64"))
torch.Tensor.device.__get__(Tensor([1, 21], "int64"))
torch.ones(1, dtype="int64", device="cuda:0")
torch.Tensor.device.__get__(Tensor([1, 21], "int64"))
torch.ones(21, dtype="int64", device="cuda:0")
torch.Tensor.cumsum(Tensor([21], "int64"), 0)
torch.Tensor.sub(Tensor([21], "int64"), 1)
torch.Tensor.__getitem__(Tensor([21], "int64"), <Unserializable: slice>)
torch.Tensor.device.__get__(Tensor([32000, 2048], "float32"))
torch.Tensor.device.__get__(Tensor([1, 21], "int64"))
torch.Tensor.__getitem__(Tensor([21], "int64"), -1)
torch.Tensor.shape.__get__(Tensor([1, 21], "int64"))
torch.Tensor.ge(Tensor([], "int64"), 21)
torch.Tensor.__bool__(Tensor([], "bool"))
torch.Tensor.shape.__get__(Tensor([1, 21], "int64"))
torch.Tensor.shape.__get__(Tensor([21], "int64"))
torch.Tensor.clone(Tensor([1, 21], "int64"), memory_format="torch.contiguous_format")
torch.Tensor.long(Tensor([1, 21], "int64"))
torch.Tensor.cumsum(Tensor([1, 21], "int64"), -1)
torch.Tensor.sub(Tensor([1, 21], "int64"), 1)
torch.Tensor.__eq__(Tensor([1, 21], "int64"), 0)
torch.Tensor.masked_fill_(Tensor([1, 21], "int64"), Tensor([1, 21], "bool"), 1)
torch.Tensor.shape.__get__(Tensor([1, 21], "int64"))
torch.Tensor.__getitem__(Tensor([1, 21], "int64"), tuple(<Unserializable: slice>, <Unserializable: slice>))
torch.Tensor.clone(Tensor([1, 21], "int64"), memory_format="torch.contiguous_format")
torch.nn.functional.embedding(Tensor([1, 21], "int64"), Tensor([32000, 2048], "float32"), padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False)
torch.Tensor.shape.__get__(Tensor([1, 21], "int64"))
torch.Tensor.ndim.__get__(Tensor([1, 21], "int64"))
torch.Tensor.device.__get__(Tensor([21], "int64"))
torch.Tensor.to(Tensor([1, 21], "int64"), device="cuda:0", dtype="bool")
torch.Tensor.shape.__get__(Tensor([21], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.shape.__get__(Tensor([21], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 21], "bool"))
torch.Tensor.shape.__get__(Tensor([1, 21], "bool"))
torch.Tensor.all(Tensor([1, 21], "bool"))
torch.Tensor.__bool__(Tensor([], "bool"))
torch._C._set_grad_enabled(False)
torch.Tensor.__getitem__(Tensor([32], "float32"), tuple(None, <Unserializable: slice>, None))
torch.Tensor.float(Tensor([1, 32, 1], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 21], "int64"))
torch.Tensor.expand(Tensor([1, 32, 1], "float32"), 1, -1, 1)
torch.Tensor.device.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 32, 1], "float32"), "cuda:0")
torch.Tensor.__getitem__(Tensor([1, 21], "int64"), tuple(<Unserializable: slice>, None, <Unserializable: slice>))
torch.Tensor.float(Tensor([1, 1, 21], "int64"))
torch.Tensor.device.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.device.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.device.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.float(Tensor([1, 32, 1], "float32"))
torch.Tensor.float(Tensor([1, 1, 21], "float32"))
torch.Tensor.matmul(Tensor([1, 32, 1], "float32"), Tensor([1, 1, 21], "float32"))
torch.Tensor.transpose(Tensor([1, 32, 21], "float32"), 1, 2)
torch.cat(tuple(Tensor([1, 21, 32], "float32"), Tensor([1, 21, 32], "float32")), dim=-1)
torch.Tensor.cos(Tensor([1, 21, 64], "float32"))
torch.Tensor.mul(Tensor([1, 21, 64], "float32"), 1.0)
torch.Tensor.sin(Tensor([1, 21, 64], "float32"))
torch.Tensor.mul(Tensor([1, 21, 64], "float32"), 1.0)
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 64], "float32"), dtype="float32")
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 64], "float32"), dtype="float32")
torch._C._set_grad_enabled(False)
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 2048], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 32, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 32, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 32, 21, 32], "float32"), Tensor([1, 32, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 4, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 4, 21, 32], "float32"), Tensor([1, 4, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.nn.functional.scaled_dot_product_attention(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), attn_mask=None, dropout_p=0.0, scale=0.125, is_causal=True, enable_gqa=True)
torch.Tensor.transpose(Tensor([1, 32, 21, 64], "float32"), 1, 2)
torch.Tensor.contiguous(Tensor([1, 21, 32, 64], "float32"))
torch.Tensor.reshape(Tensor([1, 21, 32, 64], "float32"), 1, 21, -1)
torch.Tensor.contiguous(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.nn.functional.silu(Tensor([1, 21, 5632], "float32"), inplace=False)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.Tensor.mul(Tensor([1, 21, 5632], "float32"), Tensor([1, 21, 5632], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 5632], "float32"), Tensor([2048, 5632], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 2048], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 32, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 32, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 32, 21, 32], "float32"), Tensor([1, 32, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 4, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 4, 21, 32], "float32"), Tensor([1, 4, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.nn.functional.scaled_dot_product_attention(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), attn_mask=None, dropout_p=0.0, scale=0.125, is_causal=True, enable_gqa=True)
torch.Tensor.transpose(Tensor([1, 32, 21, 64], "float32"), 1, 2)
torch.Tensor.contiguous(Tensor([1, 21, 32, 64], "float32"))
torch.Tensor.reshape(Tensor([1, 21, 32, 64], "float32"), 1, 21, -1)
torch.Tensor.contiguous(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.nn.functional.silu(Tensor([1, 21, 5632], "float32"), inplace=False)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.Tensor.mul(Tensor([1, 21, 5632], "float32"), Tensor([1, 21, 5632], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 5632], "float32"), Tensor([2048, 5632], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 2048], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 32, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 32, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 32, 21, 32], "float32"), Tensor([1, 32, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 4, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 4, 21, 32], "float32"), Tensor([1, 4, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.nn.functional.scaled_dot_product_attention(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), attn_mask=None, dropout_p=0.0, scale=0.125, is_causal=True, enable_gqa=True)
torch.Tensor.transpose(Tensor([1, 32, 21, 64], "float32"), 1, 2)
torch.Tensor.contiguous(Tensor([1, 21, 32, 64], "float32"))
torch.Tensor.reshape(Tensor([1, 21, 32, 64], "float32"), 1, 21, -1)
torch.Tensor.contiguous(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.nn.functional.silu(Tensor([1, 21, 5632], "float32"), inplace=False)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.Tensor.mul(Tensor([1, 21, 5632], "float32"), Tensor([1, 21, 5632], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 5632], "float32"), Tensor([2048, 5632], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 2048], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 32, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 32, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 32, 21, 32], "float32"), Tensor([1, 32, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 4, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 4, 21, 32], "float32"), Tensor([1, 4, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.nn.functional.scaled_dot_product_attention(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), attn_mask=None, dropout_p=0.0, scale=0.125, is_causal=True, enable_gqa=True)
torch.Tensor.transpose(Tensor([1, 32, 21, 64], "float32"), 1, 2)
torch.Tensor.contiguous(Tensor([1, 21, 32, 64], "float32"))
torch.Tensor.reshape(Tensor([1, 21, 32, 64], "float32"), 1, 21, -1)
torch.Tensor.contiguous(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.nn.functional.silu(Tensor([1, 21, 5632], "float32"), inplace=False)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.Tensor.mul(Tensor([1, 21, 5632], "float32"), Tensor([1, 21, 5632], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 5632], "float32"), Tensor([2048, 5632], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 2048], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 32, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 32, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 32, 21, 32], "float32"), Tensor([1, 32, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 4, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 4, 21, 32], "float32"), Tensor([1, 4, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.nn.functional.scaled_dot_product_attention(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), attn_mask=None, dropout_p=0.0, scale=0.125, is_causal=True, enable_gqa=True)
torch.Tensor.transpose(Tensor([1, 32, 21, 64], "float32"), 1, 2)
torch.Tensor.contiguous(Tensor([1, 21, 32, 64], "float32"))
torch.Tensor.reshape(Tensor([1, 21, 32, 64], "float32"), 1, 21, -1)
torch.Tensor.contiguous(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.nn.functional.silu(Tensor([1, 21, 5632], "float32"), inplace=False)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.Tensor.mul(Tensor([1, 21, 5632], "float32"), Tensor([1, 21, 5632], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 5632], "float32"), Tensor([2048, 5632], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 2048], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 32, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 32, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 32, 21, 32], "float32"), Tensor([1, 32, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 4, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 4, 21, 32], "float32"), Tensor([1, 4, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.nn.functional.scaled_dot_product_attention(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), attn_mask=None, dropout_p=0.0, scale=0.125, is_causal=True, enable_gqa=True)
torch.Tensor.transpose(Tensor([1, 32, 21, 64], "float32"), 1, 2)
torch.Tensor.contiguous(Tensor([1, 21, 32, 64], "float32"))
torch.Tensor.reshape(Tensor([1, 21, 32, 64], "float32"), 1, 21, -1)
torch.Tensor.contiguous(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.nn.functional.silu(Tensor([1, 21, 5632], "float32"), inplace=False)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.Tensor.mul(Tensor([1, 21, 5632], "float32"), Tensor([1, 21, 5632], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 5632], "float32"), Tensor([2048, 5632], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 2048], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 32, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 32, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 32, 21, 32], "float32"), Tensor([1, 32, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 4, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 4, 21, 32], "float32"), Tensor([1, 4, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.nn.functional.scaled_dot_product_attention(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), attn_mask=None, dropout_p=0.0, scale=0.125, is_causal=True, enable_gqa=True)
torch.Tensor.transpose(Tensor([1, 32, 21, 64], "float32"), 1, 2)
torch.Tensor.contiguous(Tensor([1, 21, 32, 64], "float32"))
torch.Tensor.reshape(Tensor([1, 21, 32, 64], "float32"), 1, 21, -1)
torch.Tensor.contiguous(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.nn.functional.silu(Tensor([1, 21, 5632], "float32"), inplace=False)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.Tensor.mul(Tensor([1, 21, 5632], "float32"), Tensor([1, 21, 5632], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 5632], "float32"), Tensor([2048, 5632], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 2048], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 32, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 32, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 32, 21, 32], "float32"), Tensor([1, 32, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 4, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 4, 21, 32], "float32"), Tensor([1, 4, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.nn.functional.scaled_dot_product_attention(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), attn_mask=None, dropout_p=0.0, scale=0.125, is_causal=True, enable_gqa=True)
torch.Tensor.transpose(Tensor([1, 32, 21, 64], "float32"), 1, 2)
torch.Tensor.contiguous(Tensor([1, 21, 32, 64], "float32"))
torch.Tensor.reshape(Tensor([1, 21, 32, 64], "float32"), 1, 21, -1)
torch.Tensor.contiguous(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.nn.functional.silu(Tensor([1, 21, 5632], "float32"), inplace=False)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.Tensor.mul(Tensor([1, 21, 5632], "float32"), Tensor([1, 21, 5632], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 5632], "float32"), Tensor([2048, 5632], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 2048], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 32, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 32, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 32, 21, 32], "float32"), Tensor([1, 32, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 4, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 4, 21, 32], "float32"), Tensor([1, 4, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.nn.functional.scaled_dot_product_attention(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), attn_mask=None, dropout_p=0.0, scale=0.125, is_causal=True, enable_gqa=True)
torch.Tensor.transpose(Tensor([1, 32, 21, 64], "float32"), 1, 2)
torch.Tensor.contiguous(Tensor([1, 21, 32, 64], "float32"))
torch.Tensor.reshape(Tensor([1, 21, 32, 64], "float32"), 1, 21, -1)
torch.Tensor.contiguous(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.nn.functional.silu(Tensor([1, 21, 5632], "float32"), inplace=False)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.Tensor.mul(Tensor([1, 21, 5632], "float32"), Tensor([1, 21, 5632], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 5632], "float32"), Tensor([2048, 5632], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 2048], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 32, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 32, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 32, 21, 32], "float32"), Tensor([1, 32, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 4, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 4, 21, 32], "float32"), Tensor([1, 4, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.nn.functional.scaled_dot_product_attention(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), attn_mask=None, dropout_p=0.0, scale=0.125, is_causal=True, enable_gqa=True)
torch.Tensor.transpose(Tensor([1, 32, 21, 64], "float32"), 1, 2)
torch.Tensor.contiguous(Tensor([1, 21, 32, 64], "float32"))
torch.Tensor.reshape(Tensor([1, 21, 32, 64], "float32"), 1, 21, -1)
torch.Tensor.contiguous(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.nn.functional.silu(Tensor([1, 21, 5632], "float32"), inplace=False)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.Tensor.mul(Tensor([1, 21, 5632], "float32"), Tensor([1, 21, 5632], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 5632], "float32"), Tensor([2048, 5632], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 2048], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 32, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 32, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 32, 21, 32], "float32"), Tensor([1, 32, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 4, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 4, 21, 32], "float32"), Tensor([1, 4, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.nn.functional.scaled_dot_product_attention(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), attn_mask=None, dropout_p=0.0, scale=0.125, is_causal=True, enable_gqa=True)
torch.Tensor.transpose(Tensor([1, 32, 21, 64], "float32"), 1, 2)
torch.Tensor.contiguous(Tensor([1, 21, 32, 64], "float32"))
torch.Tensor.reshape(Tensor([1, 21, 32, 64], "float32"), 1, 21, -1)
torch.Tensor.contiguous(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.nn.functional.silu(Tensor([1, 21, 5632], "float32"), inplace=False)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.Tensor.mul(Tensor([1, 21, 5632], "float32"), Tensor([1, 21, 5632], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 5632], "float32"), Tensor([2048, 5632], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 2048], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 32, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 32, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 32, 21, 32], "float32"), Tensor([1, 32, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 4, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 4, 21, 32], "float32"), Tensor([1, 4, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.nn.functional.scaled_dot_product_attention(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), attn_mask=None, dropout_p=0.0, scale=0.125, is_causal=True, enable_gqa=True)
torch.Tensor.transpose(Tensor([1, 32, 21, 64], "float32"), 1, 2)
torch.Tensor.contiguous(Tensor([1, 21, 32, 64], "float32"))
torch.Tensor.reshape(Tensor([1, 21, 32, 64], "float32"), 1, 21, -1)
torch.Tensor.contiguous(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.nn.functional.silu(Tensor([1, 21, 5632], "float32"), inplace=False)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.Tensor.mul(Tensor([1, 21, 5632], "float32"), Tensor([1, 21, 5632], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 5632], "float32"), Tensor([2048, 5632], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 2048], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 32, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 32, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 32, 21, 32], "float32"), Tensor([1, 32, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 4, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 4, 21, 32], "float32"), Tensor([1, 4, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.nn.functional.scaled_dot_product_attention(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), attn_mask=None, dropout_p=0.0, scale=0.125, is_causal=True, enable_gqa=True)
torch.Tensor.transpose(Tensor([1, 32, 21, 64], "float32"), 1, 2)
torch.Tensor.contiguous(Tensor([1, 21, 32, 64], "float32"))
torch.Tensor.reshape(Tensor([1, 21, 32, 64], "float32"), 1, 21, -1)
torch.Tensor.contiguous(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.nn.functional.silu(Tensor([1, 21, 5632], "float32"), inplace=False)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.Tensor.mul(Tensor([1, 21, 5632], "float32"), Tensor([1, 21, 5632], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 5632], "float32"), Tensor([2048, 5632], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 2048], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 32, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 32, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 32, 21, 32], "float32"), Tensor([1, 32, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 4, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 4, 21, 32], "float32"), Tensor([1, 4, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.nn.functional.scaled_dot_product_attention(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), attn_mask=None, dropout_p=0.0, scale=0.125, is_causal=True, enable_gqa=True)
torch.Tensor.transpose(Tensor([1, 32, 21, 64], "float32"), 1, 2)
torch.Tensor.contiguous(Tensor([1, 21, 32, 64], "float32"))
torch.Tensor.reshape(Tensor([1, 21, 32, 64], "float32"), 1, 21, -1)
torch.Tensor.contiguous(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.nn.functional.silu(Tensor([1, 21, 5632], "float32"), inplace=False)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.Tensor.mul(Tensor([1, 21, 5632], "float32"), Tensor([1, 21, 5632], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 5632], "float32"), Tensor([2048, 5632], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 2048], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 32, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 32, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 32, 21, 32], "float32"), Tensor([1, 32, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 4, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 4, 21, 32], "float32"), Tensor([1, 4, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.nn.functional.scaled_dot_product_attention(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), attn_mask=None, dropout_p=0.0, scale=0.125, is_causal=True, enable_gqa=True)
torch.Tensor.transpose(Tensor([1, 32, 21, 64], "float32"), 1, 2)
torch.Tensor.contiguous(Tensor([1, 21, 32, 64], "float32"))
torch.Tensor.reshape(Tensor([1, 21, 32, 64], "float32"), 1, 21, -1)
torch.Tensor.contiguous(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.nn.functional.silu(Tensor([1, 21, 5632], "float32"), inplace=False)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.Tensor.mul(Tensor([1, 21, 5632], "float32"), Tensor([1, 21, 5632], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 5632], "float32"), Tensor([2048, 5632], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 2048], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 32, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 32, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 32, 21, 32], "float32"), Tensor([1, 32, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 4, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 4, 21, 32], "float32"), Tensor([1, 4, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.nn.functional.scaled_dot_product_attention(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), attn_mask=None, dropout_p=0.0, scale=0.125, is_causal=True, enable_gqa=True)
torch.Tensor.transpose(Tensor([1, 32, 21, 64], "float32"), 1, 2)
torch.Tensor.contiguous(Tensor([1, 21, 32, 64], "float32"))
torch.Tensor.reshape(Tensor([1, 21, 32, 64], "float32"), 1, 21, -1)
torch.Tensor.contiguous(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.nn.functional.silu(Tensor([1, 21, 5632], "float32"), inplace=False)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.Tensor.mul(Tensor([1, 21, 5632], "float32"), Tensor([1, 21, 5632], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 5632], "float32"), Tensor([2048, 5632], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 2048], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 32, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 32, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 32, 21, 32], "float32"), Tensor([1, 32, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 4, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 4, 21, 32], "float32"), Tensor([1, 4, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.nn.functional.scaled_dot_product_attention(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), attn_mask=None, dropout_p=0.0, scale=0.125, is_causal=True, enable_gqa=True)
torch.Tensor.transpose(Tensor([1, 32, 21, 64], "float32"), 1, 2)
torch.Tensor.contiguous(Tensor([1, 21, 32, 64], "float32"))
torch.Tensor.reshape(Tensor([1, 21, 32, 64], "float32"), 1, 21, -1)
torch.Tensor.contiguous(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.nn.functional.silu(Tensor([1, 21, 5632], "float32"), inplace=False)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.Tensor.mul(Tensor([1, 21, 5632], "float32"), Tensor([1, 21, 5632], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 5632], "float32"), Tensor([2048, 5632], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 2048], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 32, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 32, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 32, 21, 32], "float32"), Tensor([1, 32, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 4, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 4, 21, 32], "float32"), Tensor([1, 4, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.nn.functional.scaled_dot_product_attention(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), attn_mask=None, dropout_p=0.0, scale=0.125, is_causal=True, enable_gqa=True)
torch.Tensor.transpose(Tensor([1, 32, 21, 64], "float32"), 1, 2)
torch.Tensor.contiguous(Tensor([1, 21, 32, 64], "float32"))
torch.Tensor.reshape(Tensor([1, 21, 32, 64], "float32"), 1, 21, -1)
torch.Tensor.contiguous(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.nn.functional.silu(Tensor([1, 21, 5632], "float32"), inplace=False)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.Tensor.mul(Tensor([1, 21, 5632], "float32"), Tensor([1, 21, 5632], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 5632], "float32"), Tensor([2048, 5632], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 2048], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 32, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 32, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 32, 21, 32], "float32"), Tensor([1, 32, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 4, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 4, 21, 32], "float32"), Tensor([1, 4, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.nn.functional.scaled_dot_product_attention(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), attn_mask=None, dropout_p=0.0, scale=0.125, is_causal=True, enable_gqa=True)
torch.Tensor.transpose(Tensor([1, 32, 21, 64], "float32"), 1, 2)
torch.Tensor.contiguous(Tensor([1, 21, 32, 64], "float32"))
torch.Tensor.reshape(Tensor([1, 21, 32, 64], "float32"), 1, 21, -1)
torch.Tensor.contiguous(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.nn.functional.silu(Tensor([1, 21, 5632], "float32"), inplace=False)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.Tensor.mul(Tensor([1, 21, 5632], "float32"), Tensor([1, 21, 5632], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 5632], "float32"), Tensor([2048, 5632], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 2048], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 32, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 32, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 32, 21, 32], "float32"), Tensor([1, 32, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 4, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 4, 21, 32], "float32"), Tensor([1, 4, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.nn.functional.scaled_dot_product_attention(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), attn_mask=None, dropout_p=0.0, scale=0.125, is_causal=True, enable_gqa=True)
torch.Tensor.transpose(Tensor([1, 32, 21, 64], "float32"), 1, 2)
torch.Tensor.contiguous(Tensor([1, 21, 32, 64], "float32"))
torch.Tensor.reshape(Tensor([1, 21, 32, 64], "float32"), 1, 21, -1)
torch.Tensor.contiguous(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.nn.functional.silu(Tensor([1, 21, 5632], "float32"), inplace=False)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.Tensor.mul(Tensor([1, 21, 5632], "float32"), Tensor([1, 21, 5632], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 5632], "float32"), Tensor([2048, 5632], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 2048], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 32, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 32, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 32, 21, 32], "float32"), Tensor([1, 32, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 4, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 4, 21, 32], "float32"), Tensor([1, 4, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.nn.functional.scaled_dot_product_attention(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), attn_mask=None, dropout_p=0.0, scale=0.125, is_causal=True, enable_gqa=True)
torch.Tensor.transpose(Tensor([1, 32, 21, 64], "float32"), 1, 2)
torch.Tensor.contiguous(Tensor([1, 21, 32, 64], "float32"))
torch.Tensor.reshape(Tensor([1, 21, 32, 64], "float32"), 1, 21, -1)
torch.Tensor.contiguous(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.nn.functional.silu(Tensor([1, 21, 5632], "float32"), inplace=False)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.Tensor.mul(Tensor([1, 21, 5632], "float32"), Tensor([1, 21, 5632], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 5632], "float32"), Tensor([2048, 5632], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 2048], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 32, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([256, 2048], "float32"), None)
torch.Tensor.view(Tensor([1, 21, 256], "float32"), tuple(1, 21, -1, 64))
torch.Tensor.transpose(Tensor([1, 21, 4, 64], "float32"), 1, 2)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.unsqueeze(Tensor([1, 21, 64], "float32"), 1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 32, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 32, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 32, 21, 32], "float32"), Tensor([1, 32, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.shape.__get__(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.__getitem__(Tensor([1, 4, 21, 64], "float32"), tuple(<Unserializable: ellipsis>, <Unserializable: slice>))
torch.Tensor.neg(Tensor([1, 4, 21, 32], "float32"))
torch.cat(tuple(Tensor([1, 4, 21, 32], "float32"), Tensor([1, 4, 21, 32], "float32")), dim=-1)
torch.Tensor.mul(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 1, 21, 64], "float32"))
torch.Tensor.add(Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 32, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.contiguous(Tensor([1, 4, 21, 64], "float32"))
torch.Tensor.shape.__get__(Tensor([1, 32, 21, 64], "float32"))
torch.nn.functional.scaled_dot_product_attention(Tensor([1, 32, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), Tensor([1, 4, 21, 64], "float32"), attn_mask=None, dropout_p=0.0, scale=0.125, is_causal=True, enable_gqa=True)
torch.Tensor.transpose(Tensor([1, 32, 21, 64], "float32"), 1, 2)
torch.Tensor.contiguous(Tensor([1, 21, 32, 64], "float32"))
torch.Tensor.reshape(Tensor([1, 21, 32, 64], "float32"), 1, 21, -1)
torch.Tensor.contiguous(Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([2048, 2048], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.nn.functional.silu(Tensor([1, 21, 5632], "float32"), inplace=False)
torch.nn.functional.linear(Tensor([1, 21, 2048], "float32"), Tensor([5632, 2048], "float32"), None)
torch.Tensor.mul(Tensor([1, 21, 5632], "float32"), Tensor([1, 21, 5632], "float32"))
torch.nn.functional.linear(Tensor([1, 21, 5632], "float32"), Tensor([2048, 5632], "float32"), None)
torch.Tensor.add(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.dtype.__get__(Tensor([1, 21, 2048], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.pow(Tensor([1, 21, 2048], "float32"), 2)
torch.Tensor.mean(Tensor([1, 21, 2048], "float32"), -1, keepdim=True)
torch.Tensor.add(Tensor([1, 21, 1], "float32"), 1e-05)
torch.rsqrt(Tensor([1, 21, 1], "float32"))
torch.Tensor.mul(Tensor([1, 21, 2048], "float32"), Tensor([1, 21, 1], "float32"))
torch.Tensor.to(Tensor([1, 21, 2048], "float32"), "float32")
torch.Tensor.mul(Tensor([2048], "float32"), Tensor([1, 21, 2048], "float32"))
torch.Tensor.__getitem__(Tensor([1, 21, 2048], "float32"), tuple(<Unserializable: slice>, <Unserializable: slice>, <Unserializable: slice>))
torch.nn.functional.linear(Tensor([1, 1, 2048], "float32"), Tensor([32000, 2048], "float32"), None)
torch.Tensor.shape.__get__(Tensor([1, 21], "int64"))
torch.Tensor.new_ones(Tensor([1, 21], "int64"), tuple(1, 1))
torch.cat(list[Tensor([1, 21], "int64"), Tensor([1, 1], "int64")], dim=-1)
torch.Tensor.__getitem__(Tensor([21], "int64"), <Unserializable: slice>)
torch.Tensor.add(Tensor([1], "int64"), 1)
torch.Tensor.__getitem__(Tensor([1, 1, 32000], "float32"), tuple(<Unserializable: slice>, -1, <Unserializable: slice>))
torch.Tensor.device.__get__(Tensor([1, 21], "int64"))
torch.Tensor.to(Tensor([1, 32000], "float32"), copy=True, dtype="float32", device="cuda:0")
torch.Tensor.div(Tensor([1, 32000], "float32"), 0.7)
torch.Tensor.size(Tensor([1, 32000], "float32"), -1)
torch.topk(Tensor([1, 32000], "float32"), 50)
torch.Tensor.__getitem__(Tensor([1, 50], "float32"), tuple(<Unserializable: ellipsis>, -1, None))
torch.Tensor.lt(Tensor([1, 32000], "float32"), Tensor([1, 1], "float32"))
torch.Tensor.masked_fill(Tensor([1, 32000], "float32"), Tensor([1, 32000], "bool"), -inf)
torch.nn.functional.softmax(Tensor([1, 32000], "float32"), dim=-1, _stacklevel=3, dtype=None)
torch.multinomial(Tensor([1, 32000], "float32"), num_samples=1)
torch.Tensor.squeeze(Tensor([1, 1], "int64"), 1)
torch.Tensor.mul(Tensor([1], "int64"), Tensor([1], "int64"))
torch.Tensor.__rsub__(Tensor([1], "int64"), 1)
torch.Tensor.mul(Tensor([], "int64"), Tensor([1], "int64"))
torch.Tensor.add(Tensor([1], "int64"), Tensor([1], "int64"))
torch.Tensor.__getitem__(Tensor([1], "int64"), tuple(<Unserializable: slice>, None))
torch.cat(list[Tensor([1, 21], "int64"), Tensor([1, 1], "int64")], dim=-1)
torch.Tensor.shape.__get__(Tensor([1, 22], "int64"))
torch.Tensor.device.__get__(Tensor([1, 22], "int64"))
torch.full(tuple(1), False, device="cuda:0", dtype="bool")
torch.Tensor.shape.__get__(Tensor([1, 22], "int64"))
torch.Tensor.shape.__get__(Tensor([1, 22], "int64"))
torch.Tensor.device.__get__(Tensor([1, 22], "int64"))
torch.full(tuple(1), False, device="cuda:0", dtype="bool")
torch.Tensor.__or__(Tensor([1], "bool"), Tensor([1], "bool"))
torch.Tensor.device.__get__(Tensor([1, 22], "int64"))
torch.Tensor.to(Tensor([1], "int64"), "cuda:0")
torch.Tensor.__getitem__(Tensor([1, 22], "int64"), tuple(<Unserializable: slice>, -1))
torch.Tensor.device.__get__(Tensor([1], "int64"))
torch.isin(Tensor([1], "int64"), Tensor([1], "int64"))
torch.Tensor.__or__(Tensor([1], "bool"), Tensor([1], "bool"))
torch.Tensor.__invert__(Tensor([1], "bool"))
torch.Tensor.__and__(Tensor([1], "int64"), Tensor([1], "bool"))
torch.Tensor.max(Tensor([1], "int64"))
torch.Tensor.__eq__(Tensor([], "int64"), 0)
torch.Tensor.device.__get__(Tensor([1, 22], "int64"))
torch.Tensor.__bool__(Tensor([], "bool"))
torch._C._set_grad_enabled(True)
